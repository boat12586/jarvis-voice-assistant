#!/usr/bin/env python3
"""
üéôÔ∏è JARVIS Enhanced Voice System
‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡∏î‡πâ‡∏ß‡∏¢ Whisper ‡πÅ‡∏•‡∏∞ TTS ‡∏à‡∏£‡∏¥‡∏á
"""

import logging
import time
import threading
import queue
import wave
import io
from pathlib import Path
from typing import Dict, Any, Optional
import sounddevice as sd
import numpy as np
import yaml

try:
    from faster_whisper import WhisperModel
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    logging.warning("Faster-Whisper not available")

try:
    from TTS.api import TTS
    TTS_AVAILABLE = True
except ImportError:
    TTS_AVAILABLE = False
    logging.warning("TTS not available")

# Enhanced AI with more responses
class EnhancedAI:
    """AI ‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô"""
    
    def __init__(self):
        self.responses = {
            'en': {
                'greetings': [
                    "Hello! I'm JARVIS, your voice assistant. How can I help you?",
                    "Good day! JARVIS at your service. What can I do for you?",
                    "Hi there! I'm ready to assist you."
                ],
                'time': [
                    f"The current time is {time.strftime('%H:%M:%S')}",
                    f"It's {time.strftime('%H:%M')} right now",
                    f"The time is {time.strftime('%H:%M:%S')}"
                ],
                'date': [
                    f"Today is {time.strftime('%Y-%m-%d')}",
                    f"The date is {time.strftime('%B %d, %Y')}",
                    f"Today's date is {time.strftime('%A, %B %d, %Y')}"
                ],
                'weather': [
                    "I don't have weather data access yet, but I'm working on it!",
                    "Weather integration is coming soon!",
                    "I can't check the weather right now, but it's a great feature for the future!"
                ],
                'capabilities': [
                    "I can help you with time, date, simple conversations, and voice commands!",
                    "I'm capable of voice recognition, text responses, and basic assistance.",
                    "My current abilities include voice interaction, time/date queries, and conversation."
                ],
                'thanks': [
                    "You're welcome! Happy to help!",
                    "My pleasure! Is there anything else?",
                    "Glad I could assist you!"
                ],
                'goodbye': [
                    "Goodbye! Have a great day!",
                    "See you later! Take care!",
                    "Farewell! Come back anytime!"
                ],
                'default': [
                    "I understand. How can I assist you further?",
                    "Interesting! What else can I help you with?",
                    "I'm here to help. What would you like to know?"
                ]
            },
            'th': {
                'greetings': [
                    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏° JARVIS ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏ß‡∏±‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏° JARVIS ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'time': [
                    f"‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ {time.strftime('%H:%M:%S')} ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö",
                    f"‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ß‡∏•‡∏≤ {time.strftime('%H:%M')} ‡∏Ñ‡∏£‡∏±‡∏ö",
                    f"‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ {time.strftime('%H:%M:%S')} ‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'date': [
                    f"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà {time.strftime('%d-%m-%Y')} ‡∏Ñ‡∏£‡∏±‡∏ö",
                    f"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ {time.strftime('%d %B %Y')} ‡∏Ñ‡∏£‡∏±‡∏ö",
                    f"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà {time.strftime('%A %d %B %Y')} ‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'weather': [
                    "‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏¢‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏∞‡∏°‡∏≤‡πÄ‡∏£‡πá‡∏ß‡πÜ ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏ú‡∏°‡∏¢‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'capabilities': [
                    "‡∏ú‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏ß‡∏•‡∏≤ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏ú‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏°‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤/‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'thanks': [
                    "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏î‡∏µ‡πÉ‡∏à‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏µ‡∏Å‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏î‡∏µ‡πÉ‡∏à‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏±‡∏ö!"
                ],
                'goodbye': [
                    "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏ö‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏±‡∏ö ‡∏î‡∏π‡πÅ‡∏•‡∏ï‡∏±‡∏ß‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡πÉ‡∏´‡∏°‡πà‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö"
                ],
                'default': [
                    "‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏µ‡∏Å‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à‡∏Ñ‡∏£‡∏±‡∏ö ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö",
                    "‡∏ú‡∏°‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏≠‡∏¢‡∏≤‡∏Å‡∏ó‡∏£‡∏≤‡∏ö‡∏≠‡∏∞‡πÑ‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏£‡∏±‡∏ö"
                ]
            }
        }
        
        # Conversation memory
        self.conversation_history = []
        self.user_preferences = {}
    
    def get_response(self, text: str, language: str = 'en') -> str:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏â‡∏•‡∏≤‡∏î‡∏Ç‡∏∂‡πâ‡∏ô"""
        import random
        
        text_lower = text.lower()
        lang_responses = self.responses.get(language, self.responses['en'])
        
        # Add to conversation history
        self.conversation_history.append({
            'user': text,
            'timestamp': time.time(),
            'language': language
        })
        
        # Keep only last 10 conversations
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]
        
        # Enhanced keyword matching with random responses
        if any(word in text_lower for word in ['hello', 'hi', 'hey', '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ', '‡∏´‡∏ß‡∏±‡∏î‡∏î‡∏µ']):
            return random.choice(lang_responses['greetings'])
        elif any(word in text_lower for word in ['time', '‡πÄ‡∏ß‡∏•‡∏≤', '‡∏Å‡∏µ‡πà‡πÇ‡∏°‡∏á']):
            return random.choice(lang_responses['time'])
        elif any(word in text_lower for word in ['date', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ']):
            return random.choice(lang_responses['date'])
        elif any(word in text_lower for word in ['weather', '‡∏≠‡∏≤‡∏Å‡∏≤‡∏®', '‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®']):
            return random.choice(lang_responses['weather'])
        elif any(word in text_lower for word in ['what can you do', 'capabilities', '‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á', '‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ']):
            return random.choice(lang_responses['capabilities'])
        elif any(word in text_lower for word in ['thank', 'thanks', '‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì', '‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à']):
            return random.choice(lang_responses['thanks'])
        elif any(word in text_lower for word in ['bye', 'goodbye', '‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô', '‡∏ö‡∏≤‡∏¢']):
            return random.choice(lang_responses['goodbye'])
        else:
            return random.choice(lang_responses['default'])

# Enhanced Speech Recognition
class EnhancedSpeechRecognition:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß"""
    
    def __init__(self, model_size="base"):
        self.logger = logging.getLogger(__name__)
        
        if WHISPER_AVAILABLE:
            try:
                self.logger.info(f"üß† Loading Whisper model: {model_size}")
                self.model = WhisperModel(model_size, device="cpu")
                self.available = True
                self.logger.info("‚úÖ Whisper model loaded successfully")
            except Exception as e:
                self.logger.error(f"‚ùå Failed to load Whisper: {e}")
                self.available = False
        else:
            self.logger.warning("‚ö†Ô∏è Whisper not available - using mock recognition")
            self.available = False
    
    def transcribe_audio(self, audio_data: np.ndarray, sample_rate: int = 16000) -> tuple[str, str, float]:
        """‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        if not self.available:
            # Mock transcription for testing
            mock_texts = ["Hello JARVIS", "What time is it", "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢"]
            import random
            text = random.choice(mock_texts)
            language = "th" if any(ord(c) > 127 for c in text) else "en"
            return text, language, 0.9
        
        try:
            # Convert numpy array to audio file in memory
            audio_buffer = io.BytesIO()
            
            # Normalize audio
            audio_data = audio_data.astype(np.float32)
            if np.max(np.abs(audio_data)) > 0:
                audio_data = audio_data / np.max(np.abs(audio_data))
            
            # Convert to int16
            audio_int16 = (audio_data * 32767).astype(np.int16)
            
            # Create WAV file in memory
            with wave.open(audio_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)
                wav_file.setsampwidth(2)
                wav_file.setframerate(sample_rate)
                wav_file.writeframes(audio_int16.tobytes())
            
            audio_buffer.seek(0)
            
            # Transcribe
            segments, info = self.model.transcribe(audio_buffer)
            
            # Get the first segment
            for segment in segments:
                text = segment.text.strip()
                if text:
                    return text, info.language, segment.avg_logprob
            
            return "", "en", 0.0
            
        except Exception as e:
            self.logger.error(f"‚ùå Transcription error: {e}")
            return "", "en", 0.0

# Enhanced TTS
class EnhancedTTS:
    """‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡πâ‡∏ß"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
        if TTS_AVAILABLE:
            try:
                # Initialize TTS models
                self.tts_en = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False)
                self.tts_available = True
                self.logger.info("‚úÖ TTS models loaded successfully")
            except Exception as e:
                self.logger.error(f"‚ùå Failed to load TTS: {e}")
                self.tts_available = False
        else:
            self.logger.warning("‚ö†Ô∏è TTS not available - using text output")
            self.tts_available = False
    
    def speak(self, text: str, language: str = 'en'):
        """‡∏û‡∏π‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        self.logger.info(f"üó£Ô∏è JARVIS says ({language}): {text}")
        
        if self.tts_available:
            try:
                # Generate audio file
                output_path = f"temp_tts_{int(time.time())}.wav"
                
                if language.startswith('en'):
                    self.tts_en.tts_to_file(text=text, file_path=output_path)
                else:
                    # For Thai, use English TTS for now
                    self.tts_en.tts_to_file(text=text, file_path=output_path)
                
                # Play audio (platform-specific)
                self._play_audio_file(output_path)
                
                # Clean up
                Path(output_path).unlink(missing_ok=True)
                
            except Exception as e:
                self.logger.error(f"‚ùå TTS error: {e}")
                print(f"ü§ñ JARVIS: {text}")
        else:
            print(f"ü§ñ JARVIS: {text}")
    
    def _play_audio_file(self, file_path: str):
        """‡πÄ‡∏•‡πà‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á"""
        try:
            import pygame
            pygame.mixer.init()
            pygame.mixer.music.load(file_path)
            pygame.mixer.music.play()
            
            # Wait for playback to finish
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
                
        except ImportError:
            # Fallback to system command
            import subprocess
            import platform
            
            system = platform.system()
            if system == "Windows":
                subprocess.run(["powershell", "-c", f"(New-Object Media.SoundPlayer '{file_path}').PlaySync()"])
            elif system == "Darwin":  # macOS
                subprocess.run(["afplay", file_path])
            elif system == "Linux":
                subprocess.run(["aplay", file_path])

# Enhanced Voice Activity Detection
class EnhancedVoiceDetector:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    def __init__(self, sample_rate=16000, frame_duration=30):
        self.sample_rate = sample_rate
        self.frame_duration = frame_duration
        self.frame_size = int(sample_rate * frame_duration / 1000)
        
        # Voice activity detection parameters
        self.energy_threshold = 0.01
        self.zero_crossing_threshold = 0.3
        self.speech_frames = 0
        self.min_speech_frames = 3
        
    def detect_speech(self, audio_data):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏ö‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
        # Calculate energy
        energy = np.sum(audio_data ** 2) / len(audio_data)
        
        # Calculate zero crossing rate
        zero_crossings = np.sum(np.abs(np.diff(np.sign(audio_data)))) / (2 * len(audio_data))
        
        # Check if speech is detected
        is_speech = (energy > self.energy_threshold and 
                    zero_crossings > self.zero_crossing_threshold)
        
        if is_speech:
            self.speech_frames += 1
        else:
            self.speech_frames = max(0, self.speech_frames - 1)
        
        return self.speech_frames >= self.min_speech_frames

# Main Enhanced JARVIS System
class JarvisEnhancedVoice:
    """‡∏£‡∏∞‡∏ö‡∏ö JARVIS ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    
    def __init__(self, config_path: str = "config/default_config.yaml"):
        self.logger = logging.getLogger(__name__)
        
        # Load configuration
        self.config = self._load_config(config_path)
        
        # Initialize enhanced components
        self.ai = EnhancedAI()
        self.speech_recognition = EnhancedSpeechRecognition(
            model_size=self.config.get('voice', {}).get('whisper', {}).get('model_size', 'base')
        )
        self.tts = EnhancedTTS()
        self.voice_detector = EnhancedVoiceDetector()
        
        # System state
        self.is_active = False
        self.is_listening = False
        self.conversation_active = False
        
        # Audio settings
        self.sample_rate = self.config.get('voice', {}).get('sample_rate', 16000)
        self.chunk_size = self.config.get('voice', {}).get('chunk_size', 1024)
        self.audio_queue = queue.Queue()
        self.audio_buffer = []
        
        # Statistics
        self.stats = {
            "interactions": 0,
            "voice_recognitions": 0,
            "start_time": time.time()
        }
        
        self.logger.info("‚úÖ JARVIS Enhanced Voice System initialized")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤"""
        try:
            if Path(config_path).exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f) or {}
                self.logger.info(f"‚úÖ Config loaded from {config_path}")
                return config
            else:
                self.logger.warning(f"‚ö†Ô∏è Config file not found: {config_path}")
                return {}
        except Exception as e:
            self.logger.error(f"‚ùå Config loading failed: {e}")
            return {}
    
    def start_system(self) -> bool:
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö JARVIS"""
        if self.is_active:
            self.logger.warning("‚ö†Ô∏è System already active")
            return True
        
        self.logger.info("üöÄ Starting JARVIS Enhanced Voice System...")
        
        try:
            # Check audio devices
            devices = sd.query_devices()
            self.logger.info(f"üì± Found {len(devices)} audio devices")
            
            self.is_active = True
            self.stats["start_time"] = time.time()
            
            self.logger.info("‚úÖ JARVIS Enhanced Voice is now active!")
            return True
            
        except Exception as e:
            self.logger.error(f"‚ùå System startup failed: {e}")
            return False
    
    def stop_system(self):
        """‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏∞‡∏ö‡∏ö JARVIS"""
        if not self.is_active:
            return
        
        self.logger.info("üõë Stopping JARVIS Enhanced Voice System...")
        
        self.is_active = False
        self.is_listening = False
        self.conversation_active = False
        
        self.logger.info("‚úÖ JARVIS stopped")
    
    def start_voice_conversation(self, duration: float = 5.0):
        """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á"""
        if self.is_listening:
            self.logger.warning("‚ö†Ô∏è Already listening")
            return
        
        self.logger.info(f"üé§ Starting voice conversation for {duration} seconds...")
        self.is_listening = True
        self.audio_buffer = []
        
        try:
            # Record audio
            audio_data = sd.rec(int(duration * self.sample_rate), 
                              samplerate=self.sample_rate, 
                              channels=1, 
                              dtype=np.float32)
            sd.wait()  # Wait until recording is finished
            
            self.logger.info("üîç Processing recorded audio...")
            
            # Process the recorded audio
            if len(audio_data) > 0:
                self._process_voice_input(audio_data.flatten())
            
        except Exception as e:
            self.logger.error(f"‚ùå Voice conversation error: {e}")
        finally:
            self.is_listening = False
    
    def _process_voice_input(self, audio_data: np.ndarray):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö"""
        # Check if there's actual speech
        if not self.voice_detector.detect_speech(audio_data):
            self.logger.info("üîá No speech detected")
            return
        
        self.logger.info("üé§ Speech detected, transcribing...")
        
        # Transcribe speech
        text, language, confidence = self.speech_recognition.transcribe_audio(
            audio_data, self.sample_rate
        )
        
        if text and confidence > 0.3:
            self.logger.info(f"üìù Transcribed ({language}, {confidence:.2f}): '{text}'")
            
            # Generate and speak response
            self._handle_recognized_speech(text, language)
            self.stats["voice_recognitions"] += 1
        else:
            self.logger.info("‚ùå Could not transcribe speech clearly")
    
    def _handle_recognized_speech(self, text: str, language: str):
        """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏≥‡πÑ‡∏î‡πâ"""
        # Generate response
        response = self.ai.get_response(text, language)
        
        # Speak response
        self.tts.speak(response, language)
        
        # Update statistics
        self.stats["interactions"] += 1
    
    def process_text_message(self, text: str, language: str = "en"):
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        self.logger.info(f"üí¨ Processing text: '{text}'")
        
        # Generate response
        response = self.ai.get_response(text, language)
        
        # Speak response
        self.tts.speak(response, language)
        
        # Update statistics
        self.stats["interactions"] += 1
    
    def get_status(self) -> Dict[str, Any]:
        """‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏∞‡∏ö‡∏ö"""
        uptime = time.time() - self.stats["start_time"]
        
        return {
            "active": self.is_active,
            "listening": self.is_listening,
            "conversation_active": self.conversation_active,
            "interactions": self.stats["interactions"],
            "voice_recognitions": self.stats["voice_recognitions"],
            "uptime_seconds": uptime,
            "components": {
                "speech_recognition": self.speech_recognition.available,
                "tts": self.tts.tts_available,
                "ai": True
            }
        }


def test_enhanced_voice():
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á"""
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
    
    print("üéôÔ∏è Testing JARVIS Enhanced Voice System")
    print("======================================")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á JARVIS
    jarvis = JarvisEnhancedVoice()
    
    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö
    print("\n1. Starting enhanced system...")
    if jarvis.start_system():
        print("‚úÖ Enhanced system started successfully!")
    else:
        print("‚ùå Failed to start enhanced system")
        return
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    print("\n2. Testing enhanced text responses...")
    test_messages = [
        ("Hello JARVIS, how are you today?", "en"),
        ("What time is it now?", "en"),
        ("What's today's date?", "en"),
        ("What can you do?", "en"),
        ("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö JARVIS", "th"),
        ("‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö", "th"),
        ("Thank you JARVIS", "en"),
        ("Goodbye", "en")
    ]
    
    for message, language in test_messages:
        print(f"\nTesting: '{message}' ({language})")
        jarvis.process_text_message(message, language)
        time.sleep(1)  # Brief pause between responses
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
    print("\n3. Enhanced system status:")
    status = jarvis.get_status()
    for key, value in status.items():
        print(f"   {key}: {value}")
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡∏ñ‡πâ‡∏≤‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
    print("\n4. Voice recognition test (optional)")
    print("Would you like to test voice recognition? (y/n)")
    
    # ‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏∞‡∏ö‡∏ö
    print("\n5. Stopping enhanced system...")
    jarvis.stop_system()
    print("‚úÖ Enhanced system stopped")
    
    print("\nüéâ Enhanced voice system test completed!")


if __name__ == "__main__":
    test_enhanced_voice()